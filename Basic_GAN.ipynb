{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic GAN - Generative A.I course by Ideami",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cIRHe5qQgXG"
      },
      "source": [
        "# Generative A.I course by Javier Ideami\n",
        "# Basic GAN Notebook\n",
        "\n",
        "# Read a fun article about GANS that I wrote in medium: \n",
        "# https://towardsdatascience.com/leonardo-and-the-gan-dream-f69e8553e0af?sk=c1fdf85e94c48acd61df451babc41dfe\n",
        "\n",
        "# import the libraries\n",
        "import torch, pdb\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import make_grid\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXre4xVa8cQI"
      },
      "source": [
        "# visualization function\n",
        "def show(tensor, ch=1, size=(28,28), num=16):\n",
        "  # tensor: 128 x 784\n",
        "  data=tensor.detach().cpu().view(-1,ch,*size) # 128 x 1 x 28 x 28\n",
        "  grid = make_grid(data[:num], nrow=4).permute(1,2,0)   # 1 x 28 x 28  = 28 x 28 x 1\n",
        "  plt.imshow(grid)\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbH0CPD7-MnX"
      },
      "source": [
        "# setup of the main parameters and hyperparameters\n",
        "epochs = 500\n",
        "cur_step = 0\n",
        "info_step = 300\n",
        "mean_gen_loss = 0\n",
        "mean_disc_loss = 0\n",
        "\n",
        "z_dim = 64\n",
        "lr = 0.00001\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "bs = 128\n",
        "device = 'cuda'\n",
        "\n",
        "dataloader = DataLoader(MNIST('.', download=True, transform=transforms.ToTensor()),shuffle=True, batch_size=bs)\n",
        "\n",
        "# number of steps = 60000 / 128 = 468.75"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeJ7MsFSDn9o"
      },
      "source": [
        "# declare our models\n",
        "\n",
        "# Generator\n",
        "def genBlock(inp, out):\n",
        "  return nn.Sequential(\n",
        "      nn.Linear(inp, out),\n",
        "      nn.BatchNorm1d(out),\n",
        "      nn.ReLU(inplace=True)\n",
        "  )\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, z_dim=64, i_dim=784, h_dim=128):\n",
        "    super().__init__()\n",
        "    self.gen = nn.Sequential(\n",
        "        genBlock(z_dim, h_dim), # 64, 128\n",
        "        genBlock(h_dim, h_dim*2), # 128, 256\n",
        "        genBlock(h_dim*2, h_dim*4), # 256 x 512\n",
        "        genBlock(h_dim*4, h_dim*8), # 512, 1024\n",
        "        nn.Linear(h_dim*8, i_dim), # 1024, 784 (28x28)\n",
        "        nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "  def forward(self, noise):\n",
        "       return self.gen(noise)\n",
        "\n",
        "def gen_noise(number, z_dim):\n",
        "  return torch.randn(number, z_dim).to(device)\n",
        "\n",
        "## Discriminator\n",
        "def discBlock(inp, out):\n",
        "  return nn.Sequential(\n",
        "      nn.Linear(inp, out),\n",
        "      nn.LeakyReLU(0.2)\n",
        "  )\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, i_dim=784, h_dim=256):\n",
        "    super().__init__()\n",
        "    self.disc=nn.Sequential(\n",
        "        discBlock(i_dim, h_dim*4), # 784, 1024\n",
        "        discBlock(h_dim*4, h_dim*2), # 1024, 512\n",
        "        discBlock(h_dim*2, h_dim), # 512, 256\n",
        "        nn.Linear(h_dim, 1) # 256, 1\n",
        "    )\n",
        "\n",
        "  def forward(self, image):\n",
        "      return self.disc(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seszPPbBOc1r"
      },
      "source": [
        "gen = Generator(z_dim).to(device)\n",
        "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n",
        "disc = Discriminator().to(device)\n",
        "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_9mS9dPPpNa"
      },
      "source": [
        "gen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpl4G5NEPrJQ"
      },
      "source": [
        "disc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGjXIihPReLx"
      },
      "source": [
        "x,y=next(iter(dataloader))\n",
        "print(x.shape, y.shape)\n",
        "print(y[:10])\n",
        "\n",
        "noise = gen_noise(bs, z_dim)\n",
        "fake = gen(noise)\n",
        "show(fake)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsZzz3irTSh_"
      },
      "source": [
        "# calculating the loss\n",
        "\n",
        "# generator loss\n",
        "def calc_gen_loss(loss_func, gen, disc, number, z_dim):\n",
        "   noise = gen_noise(number, z_dim)\n",
        "   fake = gen(noise)\n",
        "   pred = disc(fake)\n",
        "   targets=torch.ones_like(pred)\n",
        "   gen_loss=loss_func(pred,targets)\n",
        "\n",
        "   return gen_loss\n",
        "\n",
        "\n",
        "def calc_disc_loss(loss_func, gen, disc, number, real, z_dim):\n",
        "   noise = gen_noise(number, z_dim)\n",
        "   fake = gen(noise)\n",
        "   disc_fake = disc(fake.detach())\n",
        "   disc_fake_targets=torch.zeros_like(disc_fake)\n",
        "   disc_fake_loss=loss_func(disc_fake, disc_fake_targets)\n",
        "\n",
        "   disc_real = disc(real)\n",
        "   disc_real_targets=torch.ones_like(disc_real)\n",
        "   disc_real_loss=loss_func(disc_real, disc_real_targets)\n",
        "\n",
        "   disc_loss=(disc_fake_loss+disc_real_loss)/2\n",
        "\n",
        "   return disc_loss\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPcL8U6BXMZv"
      },
      "source": [
        "### 60000 / 128 = 468.75  = 469 steps in each epoch\n",
        "### Each step is going to process 128 images = size of the batch (except the last step)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for real, _ in tqdm(dataloader):\n",
        "    ### discriminator\n",
        "    disc_opt.zero_grad()\n",
        "\n",
        "    cur_bs=len(real) # real: 128 x 1 x 28 x 28\n",
        "    real = real.view(cur_bs, -1) # 128 x 784\n",
        "    real = real.to(device)\n",
        "\n",
        "    disc_loss = calc_disc_loss(loss_func,gen,disc,cur_bs,real,z_dim)\n",
        "    disc_loss.backward(retain_graph=True)\n",
        "    disc_opt.step()\n",
        "\n",
        "    ### generator\n",
        "    gen_opt.zero_grad()\n",
        "    gen_loss = calc_gen_loss(loss_func,gen,disc,cur_bs,z_dim)\n",
        "    gen_loss.backward(retain_graph=True)\n",
        "    gen_opt.step()\n",
        "\n",
        "    ### visualization & stats\n",
        "    mean_disc_loss+=disc_loss.item()/info_step\n",
        "    mean_gen_loss+=gen_loss.item()/info_step\n",
        "\n",
        "    if cur_step % info_step == 0 and cur_step>0:\n",
        "      fake_noise = gen_noise(cur_bs, z_dim)\n",
        "      fake = gen(fake_noise)\n",
        "      show(fake)\n",
        "      show(real)\n",
        "      print(f\"{epoch}: step {cur_step} / Gen loss: {mean_gen_loss} / disc_loss: {mean_disc_loss}\")\n",
        "      mean_gen_loss, mean_disc_loss=0,0\n",
        "    cur_step+=1\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}